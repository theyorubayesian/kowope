{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML"
   ]
  },
  {
   "source": [
    "# Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'capstone'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "source": [
    "Zindi: DSN AI Bootcamp Qualification Hackathon [data](https://zindi.africa/hackathons/dsn-ai-bootcamp-qualification-hackathon/data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from utils import get_data\n",
    "from scripts.cleaning import clean_data"
   ]
  },
  {
   "source": [
    "path = \"data/Train.csv\"\n",
    "\n",
    "try:\n",
    "    loan_dataset = Dataset.get_by_name(ws, name=\"loan_dataset\")\n",
    "except:\n",
    "    # Download the dataset and upload to datastore\n",
    "    _ = get_data(path) \n",
    "    datastore = ws.get_default_datastore()\n",
    "    datastore.upload('data', target_path='data')\n",
    "\n",
    "    # Create TabularDataset & register in workspace\n",
    "    loan_dataset = Dataset.Tabular.from_delimited_files([(datastore, (path))])\n",
    "    loan_dataset = loan_ds.register(\n",
    "        ws, name=\"loan_dataset\", create_new_version=True,\n",
    "        description=\"Dataset for Udacity Machine Learning with Azure Capstone Project\"\n",
    "    )\n",
    "    finally:\n",
    "        loan_dataset = loan_dataset.to_pandas_dataframe()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       form_field1  form_field2  form_field3  form_field4  form_field5  \\\n",
       "2800        3398.0      1.19505       1.7028       0.5238          0.0   \n",
       "20577       3124.0      2.40405       5.1528       0.0000          0.0   \n",
       "42690       3510.0      0.02380       0.0908       0.0000          0.0   \n",
       "14918          NaN          NaN       0.1646       0.0000          0.0   \n",
       "5298        3512.0      0.06575       0.7200       0.0000          0.0   \n",
       "\n",
       "       form_field6  form_field7  form_field8  form_field9  form_field10  ...  \\\n",
       "2800       18672.0    5150360.0      20617.0          NaN     5189260.0  ...   \n",
       "20577          NaN          NaN          NaN          NaN           0.0  ...   \n",
       "42690          NaN   45740954.0          NaN    8866477.0    60476663.0  ...   \n",
       "14918          NaN          NaN          NaN          NaN           0.0  ...   \n",
       "5298           0.0    1025793.0      35788.0    2226636.0     1761392.0  ...   \n",
       "\n",
       "       form_field39  form_field42  form_field43  form_field44  form_field46  \\\n",
       "2800            0.0      0.430430          4.04      0.683232           0.0   \n",
       "20577           0.0      1.026663          0.00      0.555328           0.0   \n",
       "42690           1.0      0.057893          5.05      0.369424           0.0   \n",
       "14918           NaN      1.320000          0.00           NaN           NaN   \n",
       "5298            0.0      0.220000          5.05      0.519776           0.0   \n",
       "\n",
       "       form_field47  form_field48  form_field49  form_field50  default_status  \n",
       "2800              1     15.434027      0.739973           NaN               0  \n",
       "20577             1           NaN      0.000000           NaN               1  \n",
       "42690             1           NaN      0.000000      0.255556               0  \n",
       "14918             0           NaN      0.000000           NaN               1  \n",
       "5298              0    144.546990      1.744186      0.128355               1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>form_field1</th>\n      <th>form_field2</th>\n      <th>form_field3</th>\n      <th>form_field4</th>\n      <th>form_field5</th>\n      <th>form_field6</th>\n      <th>form_field7</th>\n      <th>form_field8</th>\n      <th>form_field9</th>\n      <th>form_field10</th>\n      <th>...</th>\n      <th>form_field39</th>\n      <th>form_field42</th>\n      <th>form_field43</th>\n      <th>form_field44</th>\n      <th>form_field46</th>\n      <th>form_field47</th>\n      <th>form_field48</th>\n      <th>form_field49</th>\n      <th>form_field50</th>\n      <th>default_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2800</th>\n      <td>3398.0</td>\n      <td>1.19505</td>\n      <td>1.7028</td>\n      <td>0.5238</td>\n      <td>0.0</td>\n      <td>18672.0</td>\n      <td>5150360.0</td>\n      <td>20617.0</td>\n      <td>NaN</td>\n      <td>5189260.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.430430</td>\n      <td>4.04</td>\n      <td>0.683232</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>15.434027</td>\n      <td>0.739973</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20577</th>\n      <td>3124.0</td>\n      <td>2.40405</td>\n      <td>5.1528</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.026663</td>\n      <td>0.00</td>\n      <td>0.555328</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42690</th>\n      <td>3510.0</td>\n      <td>0.02380</td>\n      <td>0.0908</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>45740954.0</td>\n      <td>NaN</td>\n      <td>8866477.0</td>\n      <td>60476663.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.057893</td>\n      <td>5.05</td>\n      <td>0.369424</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.255556</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14918</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.1646</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.320000</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5298</th>\n      <td>3512.0</td>\n      <td>0.06575</td>\n      <td>0.7200</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1025793.0</td>\n      <td>35788.0</td>\n      <td>2226636.0</td>\n      <td>1761392.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.220000</td>\n      <td>5.05</td>\n      <td>0.519776</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>144.546990</td>\n      <td>1.744186</td>\n      <td>0.128355</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "clean_loan_dataset = clean_data(loan_dataset, threshold=0.6, dropped_columns=[\"Applicant_ID\"])\n",
    "\n",
    "# Stratified train_test_split because dataset is imbalanced\n",
    "train, test = train_test_split(\n",
    "    clean_loan_dataset,\n",
    "    test_size=0.3,\n",
    "    stratify=clean_loan_dataset.default_status,\n",
    "    random_state=42\n",
    ")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"featurization\": \"auto\",\n",
    "    \"n_cross_validations\": 4,\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"verbosity\": logging.INFO,\n",
    "} \n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    training_data=train,\n",
    "    label_column_name=\"default_status\",\n",
    "    primary_metric=\"AUC_weighted\",\n",
    "    **automl_settings\n",
    ")"
   ]
  },
  {
   "source": [
    "# Experiment Submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_4ae69141-81be-460f-a7db-0020fff16339\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      \n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|Column name                      |Missing value count              |Imputation type                  |\n",
      "+=================================+=================================+=================================+\n",
      "|form_field1                      |1789                             |mean                             |\n",
      "|form_field10                     |254                              |mean                             |\n",
      "|form_field12                     |6921                             |mean                             |\n",
      "|form_field13                     |4176                             |mean                             |\n",
      "|form_field16                     |9093                             |mean                             |\n",
      "|form_field17                     |7786                             |mean                             |\n",
      "|form_field18                     |7251                             |mean                             |\n",
      "|form_field19                     |3                                |mean                             |\n",
      "|form_field2                      |2713                             |mean                             |\n",
      "|form_field20                     |254                              |mean                             |\n",
      "|form_field21                     |11070                            |mean                             |\n",
      "|form_field22                     |14231                            |mean                             |\n",
      "|form_field24                     |9332                             |mean                             |\n",
      "|form_field25                     |3804                             |mean                             |\n",
      "|form_field26                     |5202                             |mean                             |\n",
      "|form_field27                     |6476                             |mean                             |\n",
      "|form_field28                     |254                              |mean                             |\n",
      "|form_field29                     |254                              |mean                             |\n",
      "|form_field3                      |254                              |mean                             |\n",
      "|form_field32                     |3804                             |mean                             |\n",
      "|form_field33                     |886                              |mean                             |\n",
      "|form_field34                     |254                              |mean                             |\n",
      "|form_field36                     |1432                             |mean                             |\n",
      "|form_field37                     |3804                             |mean                             |\n",
      "|form_field38                     |254                              |mean                             |\n",
      "|form_field39                     |2939                             |mean                             |\n",
      "|form_field4                      |254                              |mean                             |\n",
      "|form_field42                     |955                              |mean                             |\n",
      "|form_field43                     |406                              |mean                             |\n",
      "|form_field44                     |3771                             |mean                             |\n",
      "|form_field46                     |11175                            |mean                             |\n",
      "|form_field48                     |14581                            |mean                             |\n",
      "|form_field49                     |254                              |mean                             |\n",
      "|form_field5                      |254                              |mean                             |\n",
      "|form_field50                     |7754                             |mean                             |\n",
      "|form_field6                      |9315                             |mean                             |\n",
      "|form_field7                      |3610                             |mean                             |\n",
      "|form_field8                      |9315                             |mean                             |\n",
      "|form_field9                      |5590                             |mean                             |\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:01:25       0.8315    0.8315\n",
      "         1   MinMaxScaler RandomForest                      0:00:49       0.8069    0.8315\n",
      "         2   StandardScalerWrapper SGD                      0:00:52       0.8265    0.8315\n",
      "         3   MinMaxScaler SGD                               0:00:49       0.8246    0.8315\n",
      "         4   StandardScalerWrapper RandomForest             0:00:51       0.8173    0.8315\n",
      "         5   MaxAbsScaler SGD                               0:00:57       0.8209    0.8315\n",
      "         6   MaxAbsScaler ExtremeRandomTrees                0:00:52       0.8067    0.8315\n",
      "         7   StandardScalerWrapper SGD                      0:00:49       0.8120    0.8315\n",
      "         8   MinMaxScaler ExtremeRandomTrees                0:00:59       0.7981    0.8315\n",
      "         9   StandardScalerWrapper SGD                      0:00:47       0.8131    0.8315\n",
      "        10   MinMaxScaler SGD                               0:01:00       0.8258    0.8315\n",
      "        11   RobustScaler ExtremeRandomTrees                0:00:57       0.7742    0.8315\n",
      "        12   MaxAbsScaler RandomForest                      0:00:58       0.8137    0.8315\n",
      "        13   MaxAbsScaler SGD                               0:00:52       0.8204    0.8315\n",
      "        14   StandardScalerWrapper SGD                      0:00:45       0.7875    0.8315\n",
      "        15   MinMaxScaler RandomForest                      0:00:48       0.8028    0.8315\n",
      "        16   StandardScalerWrapper SGD                      0:00:43       0.8266    0.8315\n",
      "        17   MinMaxScaler SGD                               0:00:43       0.8263    0.8315\n",
      "        18   StandardScalerWrapper SGD                      0:00:45       0.8264    0.8315\n",
      "        19   RobustScaler ExtremeRandomTrees                0:01:06       0.7929    0.8315\n",
      "        20   MinMaxScaler SGD                               0:00:44       0.8220    0.8315\n",
      "        21                                                  0:10:06          nan    0.8315\n",
      "ERROR:                                                 \n",
      "        22   VotingEnsemble                                 0:01:55       0.8342    0.8342\n",
      "        23   StackEnsemble                                  0:02:11       0.8334    0.8342\n",
      "Stopping criteria reached at iteration 24. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d42b9dc3c4e143d89feb1fa884f7cc62"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/aml.mini.widget.v1": "\"ClientRequestError(\\\"Error occurred in request., ConnectionError: HTTPSConnectionPool(host='eastus.experiments.azureml.net', port=443): Max retries exceeded with url: /history/v1.0/subscriptions/ba84fe8f-cc4c-483c-aa80-88843882c21d/resourceGroups/kevlar-ml-rg/providers/Microsoft.MachineLearningServices/workspaces/kevlar-ml-nunu/experimentids/4c5731f6-fb20-46eb-a361-ed7f00b86df4/runs/AutoML_4ae69141-81be-460f-a7db-0020fff16339 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001BE9961D2B0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))\\\",)\""
     },
     "metadata": {}
    }
   ],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "\n",
    "from utils import print_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_run, best_automl_model = remote_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run(Experiment: capstone,\nId: AutoML_4ae69141-81be-460f-a7db-0020fff16339_22,\nType: None,\nStatus: Completed)\n"
     ]
    }
   ],
   "source": [
    "print(automl_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "datatransformer\n{'enable_dnn': None,\n 'enable_feature_sweeping': None,\n 'feature_sweeping_config': None,\n 'feature_sweeping_timeout': None,\n 'featurization_config': None,\n 'force_text_dnn': None,\n 'is_cross_validation': None,\n 'is_onnx_compatible': None,\n 'logger': None,\n 'observer': None,\n 'task': None,\n 'working_dir': None}\n\nprefittedsoftvotingclassifier\n{'estimators': ['0', '16', '2', '18', '17', '4', '7', '14'],\n 'weights': [0.4666666666666667,\n             0.06666666666666667,\n             0.06666666666666667,\n             0.06666666666666667,\n             0.06666666666666667,\n             0.13333333333333333,\n             0.06666666666666667,\n             0.06666666666666667]}\n\n0 - maxabsscaler\n{'copy': True}\n\n0 - lightgbmclassifier\n{'boosting_type': 'gbdt',\n 'class_weight': None,\n 'colsample_bytree': 1.0,\n 'importance_type': 'split',\n 'learning_rate': 0.1,\n 'max_depth': -1,\n 'min_child_samples': 20,\n 'min_child_weight': 0.001,\n 'min_split_gain': 0.0,\n 'n_estimators': 100,\n 'n_jobs': 1,\n 'num_leaves': 31,\n 'objective': None,\n 'random_state': None,\n 'reg_alpha': 0.0,\n 'reg_lambda': 0.0,\n 'silent': True,\n 'subsample': 1.0,\n 'subsample_for_bin': 200000,\n 'subsample_freq': 0,\n 'verbose': -10}\n\n16 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': True}\n\n16 - sgdclassifierwrapper\n{'alpha': 0.0001,\n 'class_weight': 'balanced',\n 'eta0': 0.0001,\n 'fit_intercept': True,\n 'l1_ratio': 0.4897959183673469,\n 'learning_rate': 'constant',\n 'loss': 'squared_hinge',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0.6666666666666666,\n 'random_state': None,\n 'tol': 0.01}\n\n2 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': True}\n\n2 - sgdclassifierwrapper\n{'alpha': 3.0612938775510203,\n 'class_weight': 'balanced',\n 'eta0': 0.0001,\n 'fit_intercept': True,\n 'l1_ratio': 0.8979591836734693,\n 'learning_rate': 'constant',\n 'loss': 'modified_huber',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0.6666666666666666,\n 'random_state': None,\n 'tol': 0.01}\n\n18 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': True}\n\n18 - sgdclassifierwrapper\n{'alpha': 5.918408163265306,\n 'class_weight': None,\n 'eta0': 1e-05,\n 'fit_intercept': True,\n 'l1_ratio': 0.7959183673469387,\n 'learning_rate': 'constant',\n 'loss': 'modified_huber',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0.7777777777777777,\n 'random_state': None,\n 'tol': 0.001}\n\n17 - minmaxscaler\n{'copy': True, 'feature_range': (0, 1)}\n\n17 - sgdclassifierwrapper\n{'alpha': 0.40825918367346936,\n 'class_weight': 'balanced',\n 'eta0': 0.001,\n 'fit_intercept': True,\n 'l1_ratio': 0.7346938775510203,\n 'learning_rate': 'constant',\n 'loss': 'modified_huber',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0.2222222222222222,\n 'random_state': None,\n 'tol': 0.001}\n\n4 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': False}\n\n4 - randomforestclassifier\n{'bootstrap': False,\n 'ccp_alpha': 0.0,\n 'class_weight': None,\n 'criterion': 'entropy',\n 'max_depth': None,\n 'max_features': 'log2',\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 0.01,\n 'min_samples_split': 0.01,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 10,\n 'n_jobs': 1,\n 'oob_score': False,\n 'random_state': None,\n 'verbose': 0,\n 'warm_start': False}\n\n7 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': True}\n\n7 - sgdclassifierwrapper\n{'alpha': 1.4286571428571428,\n 'class_weight': None,\n 'eta0': 0.01,\n 'fit_intercept': True,\n 'l1_ratio': 0.7551020408163265,\n 'learning_rate': 'constant',\n 'loss': 'log',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0.4444444444444444,\n 'random_state': None,\n 'tol': 0.001}\n\n14 - standardscalerwrapper\n{'class_name': 'StandardScaler',\n 'copy': True,\n 'module_name': 'sklearn.preprocessing._data',\n 'with_mean': True,\n 'with_std': True}\n\n14 - sgdclassifierwrapper\n{'alpha': 4.489851020408163,\n 'class_weight': 'balanced',\n 'eta0': 0.01,\n 'fit_intercept': True,\n 'l1_ratio': 0.061224489795918366,\n 'learning_rate': 'constant',\n 'loss': 'hinge',\n 'max_iter': 1000,\n 'n_jobs': 1,\n 'penalty': 'none',\n 'power_t': 0,\n 'random_state': None,\n 'tol': 0.0001}\n\n"
     ]
    }
   ],
   "source": [
    "print_model(best_automl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['outputs/automl_model.joblib']"
      ],
      "text/html": "['outputs/automl_model.joblib']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "joblib.dump(best_automl_model, \"outputs/automl_model.joblib\")"
   ]
  },
  {
   "source": [
    "model = Model.register(\n",
    "    workspace=ws,\n",
    "    model_path=\"outputs/automl_model.joblib\",\n",
    "    model_name=\"AutoML_Voting_Ensemble\",\n",
    "    tags={\"auc\": 0.8342},\n",
    "    description=\"default_status prediction model\"\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model AutoML_Voting_Ensemble\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "name": "Python 3.6.8 64-bit",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "538e5862d24b1a3e5ce3680bcbc1bfded8e90787fb231efa28bb458150bc0bcd"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}