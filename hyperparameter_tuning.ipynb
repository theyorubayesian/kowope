{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive"
   ]
  },
  {
   "source": [
    "# Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "experiment_name = 'kowope-experiment'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "source": [
    "## Compute Targets & Run Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using existing Compute Target.\n"
     ]
    }
   ],
   "source": [
    "amlCompute_cluster_name = \"kowope-cluster\"\n",
    "\n",
    "try:\n",
    "    # Get CPU Cluster object\n",
    "    aml_compute = ws.compute_targets[amlCompute_cluster_name] \n",
    "    print(\"Using existing Compute Target.\")\n",
    "# Create if CPU Cluster Object does not exist already\n",
    "except: \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                max_nodes=4,\n",
    "                                                                vm_priority=\"lowpriority\",\n",
    "                                                                idle_seconds_before_scaledown=1800\n",
    "                                                               )\n",
    "    \n",
    "    aml_compute = ComputeTarget.create(ws, amlCompute_cluster_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Configure the training run's environment\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-your-first-pipeline#configure-the-training-runs-environment\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = aml_compute\n",
    "\n",
    "dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\"numpy\", \"pandas\", \"scikit-learn\", \"py-xgboost\"],\n",
    "    pip_packages=[\"azureml-sdk\", \"azureml-dataprep[fuse,pandas]\", \"azureml-defaults>=1.0.45\"],\n",
    "    pin_sdk_version=False\n",
    ")\n",
    "\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "aml_run_config.environment.python.conda_dependencies = dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "source": [
    "### Comment\n",
    "- The dataset used here is the **`Kowope Mart`** dataset used for the **`Data Science Nigeria`** 2020 Bootcamp qualification task. \n",
    "- The task is to predict **`defaulters`** in the retail network given a sample of **`56,000`** loan customers\n",
    "- The dataset is available through this [API](https://api.zindi.africa/v1/competitions/dsn-ai-bootcamp-qualification-hackathon/files/Train.csv).\n",
    "- The **`get_data`** function in [utils.py](utils.py) makes a POST request to the API and receives the dataset as response. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from utils import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Train.csv\"\n",
    "\n",
    "try:\n",
    "    loan_dataset = Dataset.get_by_name(ws, name=\"loan_dataset\")\n",
    "except:\n",
    "    # Download the dataset and upload to datastore\n",
    "    _ = get_data(path) \n",
    "    datastore.upload('data', target_path='data')\n",
    "\n",
    "    # Create TabularDataset & register in workspace\n",
    "    loan_dataset = Dataset.Tabular.from_delimited_files([(datastore, path)])\n",
    "    loan_dataset = loan_ds.register(\n",
    "        ws, name=\"loan_dataset\", create_new_version=True,\n",
    "        description=\"Dataset for Udacity Machine Learning with Azure Capstone Project\"\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NOTE:\n",
    "- It may be useful for this pipeline to be published so that retraining can be triggered using `HTTP requests`.\n",
    "- As such some parameters are defined using `PipelineParameter` objects so they can passed along in retraining requests"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import HyperDriveStep, PythonScriptStep"
   ]
  },
  {
   "source": [
    "## Data Cleaning Step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cleanDataStep created\n"
     ]
    }
   ],
   "source": [
    "# Step parameters\n",
    "cols_to_drop = [\"Applicant_ID\"]\n",
    "dropped_columns = PipelineParameter(name=\"dropped_columns\", default_value=str(cols_to_drop))\n",
    "threshold = PipelineParameter(name=\"threshold\", default_value=0.6)\n",
    "n_neighbors = PipelineParameter(\"n_neighbors_for_KNN_imputation\", default_value=5)\n",
    "\n",
    "# Step outputs. \n",
    "# Outputs are promoted to Dataset, registered & versioned in workspace\n",
    "intermediate_data_name_clean = \"cleaned_loan_dataset\"\n",
    "cleaned_loan_dataset = (\n",
    "    PipelineData(name=intermediate_data_name_clean, datastore=datastore)\n",
    "    .as_dataset().parse_parquet_files()\n",
    ")\n",
    "cleaned_loan_dataset = cleaned_loan_dataset.register(name=intermediate_data_name_clean, create_new_version=True)\n",
    "\n",
    "# Step configuration\n",
    "cleanDataStep = PythonScriptStep(\n",
    "    name=\"Clean Data\",\n",
    "    script_name=\"cleaning.py\",\n",
    "    source_directory=\"./scripts\",\n",
    "    arguments=[\"--input_data_name\", \"loan_dataset\",\n",
    "               \"--dropped_columns\", dropped_columns,\n",
    "               \"--threshold\", threshold,\n",
    "               \"--n_neighbors\", n_neighbors,\n",
    "               \"--output_data\", cleaned_loan_dataset\n",
    "    ],\n",
    "    inputs=[loan_dataset.as_named_input(\"loan_dataset\")],\n",
    "    outputs=[cleaned_loan_dataset],\n",
    "    compute_target=aml_compute,\n",
    "    runconfig=aml_run_config,\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print(\"cleanDataStep created\")"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NOTE:\n",
    "- This experiment develops a structure by which the AutoML Model obtained (`Voting Ensemble`) may be further improved through dedicated hyperparameter tuning\n",
    "- However, only three models are tuned here: `SGDClassifier`, `ExtraTreesClassifier`, `XGBClassifier`\n",
    "- `Estimator` objects are used for both the ExtraTreesClassifiera and XGBClassifier because of the additional `conda packages` they require which are not available in `SKLearn` objects."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.sklearn import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "estimator_sgd = SKLearn(\n",
    "    source_directory=\"./scripts\",\n",
    "    entry_script=\"train_sgd.py\",\n",
    "    compute_target=aml_compute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesClassifier\n",
    "estimator_extratrees = Estimator(\n",
    "    source_directory=\"./scripts\",\n",
    "    entry_script=\"train_extratrees.py\",\n",
    "    compute_target=aml_compute,\n",
    "    conda_packages=[\"scikit-learn\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "estimator_xgb = Estimator(\n",
    "    source_directory=\"./scripts\",\n",
    "    entry_script=\"train_xgb.py\",\n",
    "    compute_target=aml_compute,\n",
    "    conda_packages=[\"scikit-learn\", \"py-xgboost\"]\n",
    ")"
   ]
  },
  {
   "source": [
    "## Hyperparameter Tuning "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NOTE:\n",
    "- Where `BayesianParameterSampling` is used, no `early termination policy` is defined.\n",
    "- `max_total_runs` is set to a very small number (10) in all three hyperdrive configurations. Increase this to obtain better results\n",
    "- A good rule of thumb for `max_total_runs` is to use `n * len(params)` where `n` is an integer chosen by consideration of resources and time available."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import HyperDriveStep\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, loguniform, uniform\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import BayesianParameterSampling, RandomParameterSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.2, delay_evaluation=4)"
   ]
  },
  {
   "source": [
    "### SGDClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space_sgd = {\n",
    "    \"--alpha\": loguniform(0.0001, 1.0),\n",
    "    \"--l1_ratio\": uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "param_sampling_sgd = RandomParameterSampling(params_space_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_config_sgd = HyperDriveConfig(\n",
    "    estimator=estimator_sgd,\n",
    "    hyperparameter_sampling=param_sampling_sgd,\n",
    "    policy=early_termination_policy,\n",
    "    primary_metric_name=\"auc\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=10,\n",
    "    max_concurrent_runs=4\n",
    ") # 10*len(params_space_sgd),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGDClassifier Hyperdrive Step created\n"
     ]
    }
   ],
   "source": [
    "metrics_output_name_sgd =\"metrics_output_sgd\"\n",
    "metrics_data_sgd = PipelineData(name=\"metrics_data\", datastore=datastore, pipeline_output_name=metrics_output_name_sgd)\n",
    "\n",
    "hd_step_sgd = HyperDriveStep(\n",
    "    name=\"SGD_tuning\",\n",
    "    hyperdrive_config=hd_config_sgd,\n",
    "    inputs=[\n",
    "        cleaned_loan_dataset.as_named_input(intermediate_data_name_clean)\n",
    "        ],\n",
    "    estimator_entry_script_arguments=[\n",
    "        \"--input_data_name\", intermediate_data_name_clean\n",
    "    ],\n",
    "    metrics_output=metrics_data_sgd\n",
    ")\n",
    "\n",
    "print(\"SGDClassifier Hyperdrive Step created\")"
   ]
  },
  {
   "source": [
    "### XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space_xgb = {\n",
    "     \"--max_depth\": choice(range(4, 12)),\n",
    "     \"--min_child_weight\": choice(range(1, 20)),\n",
    "     \"--subsample\": uniform(0.5, 1.0),\n",
    "     \"--colsample_bytree\": uniform(0.5, 1.0),\n",
    "     \"--eta\": uniform(0.005, 0.3),\n",
    "     \"--max_delta_step\": choice(range(1, 11)),\n",
    "     \"--scale_pos_weight\": uniform(1, 4)\n",
    "    }\n",
    "\n",
    "param_sampling_xgb = BayesianParameterSampling(params_space_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_config_xgb = HyperDriveConfig(\n",
    "    estimator=estimator_xgb,\n",
    "    hyperparameter_sampling=param_sampling_xgb,\n",
    "    primary_metric_name=\"auc\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=10,\n",
    "    max_concurrent_runs=4\n",
    ") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "XGBoost Hyperdrive Step created\n"
     ]
    }
   ],
   "source": [
    "metrics_output_name_xgb =\"metrics_output_xgb\"\n",
    "metrics_data_xgb = PipelineData(name=\"metrics_data\", datastore=datastore, pipeline_output_name=metrics_output_name_xgb)\n",
    "\n",
    "hd_step_xgb = HyperDriveStep(\n",
    "    name=\"XGB_tuning\",\n",
    "    hyperdrive_config=hd_config_xgb,\n",
    "    inputs=[cleaned_loan_dataset.as_named_input(intermediate_data_name_clean)],\n",
    "    estimator_entry_script_arguments=[\n",
    "        \"--input_data_name\", intermediate_data_name_clean,\n",
    "        \"--early_stopping_rounds\", 30,\n",
    "        \"--eval_metric\", \"auc\",\n",
    "    ],\n",
    "    metrics_output=metrics_data_xgb\n",
    ")\n",
    "\n",
    "print(\"XGBoost Hyperdrive Step created\")"
   ]
  },
  {
   "source": [
    "\n",
    "### ExtraTreesClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space_extratrees = {\n",
    "    \"n_estimators\": choice(50, 100, 150, 200, 250),\n",
    "    \"min_samples_split\": uniform(0.0001, 0.01),\n",
    "    \"min_samples_leaf\": uniform(0.0001, 0.01),\n",
    "    \"max_features\": uniform(0.5, 1.0),\n",
    "    \"ccp_alpha\": uniform(0.0, 0.05)\n",
    "}\n",
    "\n",
    "param_sampling_extratrees = BayesianParameterSampling(params_space_extratrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_config_extratrees = HyperDriveConfig(\n",
    "    estimator=estimator_extratrees,\n",
    "    hyperparameter_sampling=param_sampling_extratrees,\n",
    "    primary_metric_name=\"auc\",\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "    max_total_runs=10,\n",
    "    max_concurrent_runs=4\n",
    ") # 20*len(params_space_extratrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ExtraTreesClassifier Hyperdrive Step created\n"
     ]
    }
   ],
   "source": [
    "metrics_output_name_extratrees =\"metrics_output_extratrees\"\n",
    "metrics_data_extratrees = PipelineData(name=\"metrics_data\", datastore=datastore, pipeline_output_name=metrics_output_name_extratrees)\n",
    "\n",
    "hd_step_extratrees = HyperDriveStep(\n",
    "    name=\"extratrees_tuning\",\n",
    "    hyperdrive_config=hd_config_extratrees,\n",
    "    inputs=[cleaned_loan_dataset.as_named_input(intermediate_data_name_clean)],\n",
    "    estimator_entry_script_arguments=[\n",
    "        \"--input_data_name\", intermediate_data_name_clean\n",
    "    ],\n",
    "    metrics_output=metrics_data_extratrees\n",
    ")\n",
    "\n",
    "print(\"ExtraTreesClassifier Hyperdrive Step created\")"
   ]
  },
  {
   "source": [
    "## Pipeline Submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "Created step Clean Data [ffbad4f7][3a5c3048-eb62-410e-b0a5-8390f883e68c], (This step will run and generate new outputs)Created step SGD_tuning [9d62c7d8][acbefd49-9ebe-4909-8403-327458c7402d], (This step will run and generate new outputs)\n",
      "\n",
      "Created step XGB_tuning [bee5e200][6c5dcbc3-161d-49b0-adc4-2a45a9aa3713], (This step will run and generate new outputs)\n",
      "Created step extratrees_tuning [ce546b0d][d478da59-154e-4a44-8edc-c6fae6b53843], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/kowope-experiment/runs/c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d?wsid=/subscriptions/ba84fe8f-cc4c-483c-aa80-88843882c21d/resourcegroups/kevlar-ml-rg/workspaces/kevlar-ml-nunu\n"
     ]
    }
   ],
   "source": [
    "pipeline_steps = [cleanDataStep, hd_step_sgd, hd_step_xgb, hd_step_extratrees]      #  \n",
    "\n",
    "pipeline = Pipeline(ws, steps=pipeline_steps)\n",
    "\n",
    "# When testing, use regenerate_outputs=True\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PipelineRunId: c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/kowope-experiment/runs/c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d?wsid=/subscriptions/ba84fe8f-cc4c-483c-aa80-88843882c21d/resourcegroups/kevlar-ml-rg/workspaces/kevlar-ml-nunu\n",
      "{'runId': 'c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d', 'status': 'Completed', 'startTimeUtc': '2020-11-11T13:10:34.833755Z', 'endTimeUtc': '2020-11-11T13:49:02.46808Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"dropped_columns\":\"[\\'Applicant_ID\\']\",\"threshold\":\"0.6\",\"n_neighbors_for_KNN_imputation\":\"5\"}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ej2mmhC2aAfhyks1koX9HNW9PjFvrHZPMaR0m9QzLXU%3D&st=2020-11-11T13%3A37%3A37Z&se=2020-11-11T21%3A47%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=kjDWkoOZf17%2BUmUEZrQ0PJz1CmOAQw3%2F9IhozsqwbWU%3D&st=2020-11-11T13%3A37%3A37Z&se=2020-11-11T21%3A47%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=C%2Fd3smgxnPBoL5beAeus75WoEXKI7%2B8owH00sFI9CO0%3D&st=2020-11-11T13%3A37%3A37Z&se=2020-11-11T21%3A47%3A37Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion(show_output=False)         # The logs fill up the notebook if show_output is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b259ecd7f58e43939c1f0517fdc2531b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/kowope-experiment/runs/c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d?wsid=/subscriptions/ba84fe8f-cc4c-483c-aa80-88843882c21d/resourcegroups/kevlar-ml-rg/workspaces/kevlar-ml-nunu\", \"run_id\": \"c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d\", \"run_properties\": {\"run_id\": \"c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d\", \"created_utc\": \"2020-11-11T13:10:22.467335Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{\\\"dropped_columns\\\":\\\"['Applicant_ID']\\\",\\\"threshold\\\":\\\"0.6\\\",\\\"n_neighbors_for_KNN_imputation\\\":\\\"5\\\"}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-11-11T13:49:02.46808Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=0shOQqYGiisA%2Bodq48QGRETiaIZJxd%2F40hM6Enr5bLg%3D&st=2020-11-11T18%3A39%3A58Z&se=2020-11-12T02%3A49%3A58Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=RC5pPltO0x7qJHSa0uCNH60rlEEgKWeWfSOlXUG7Q94%3D&st=2020-11-11T18%3A39%3A58Z&se=2020-11-12T02%3A49%3A58Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://kevlarmlnunu7298446017.blob.core.windows.net/azureml/ExperimentRun/dcid.c1d01c7b-2b9e-47dc-b1aa-4bf3f127168d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=xrpL3H%2FVDFOeYdVhQjkurAmSsrJtwed4K5p40%2BJLQug%3D&st=2020-11-11T18%3A39%3A58Z&se=2020-11-12T02%3A49%3A58Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:38:40\"}, \"child_runs\": [{\"run_id\": \"8f31ff6b-b933-4a85-8efa-f9509be48735\", \"name\": \"Clean Data\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:14:47.658497Z\", \"created_time\": \"2020-11-11T13:10:48.557952Z\", \"end_time\": \"2020-11-11T13:30:24.51155Z\", \"duration\": \"0:19:35\", \"run_number\": 56, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:10:48.557952Z\", \"is_reused\": \"\"}, {\"run_id\": \"8092053c-9889-4ee5-bf99-b73ef9f7447e\", \"name\": \"SGD_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:31:18.530135Z\", \"created_time\": \"2020-11-11T13:30:40.537904Z\", \"end_time\": \"2020-11-11T13:48:24.436697Z\", \"duration\": \"0:17:43\", \"run_number\": 59, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:40.537904Z\", \"is_reused\": \"\"}, {\"run_id\": \"e3d7578a-1e83-4d7a-b424-a7dfea96f3eb\", \"name\": \"XGB_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:31:21.832165Z\", \"created_time\": \"2020-11-11T13:30:39.417934Z\", \"end_time\": \"2020-11-11T13:48:49.077202Z\", \"duration\": \"0:18:09\", \"run_number\": 57, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:39.417934Z\", \"is_reused\": \"\"}, {\"run_id\": \"2865c665-1394-455b-812b-48e1974bb421\", \"name\": \"extratrees_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:30:51.60036Z\", \"created_time\": \"2020-11-11T13:30:39.622291Z\", \"end_time\": \"2020-11-11T13:47:27.682124Z\", \"duration\": \"0:16:48\", \"run_number\": 58, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:39.622291Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-11-11 13:10:48Z] Submitting 1 runs, first five are: ffbad4f7:8f31ff6b-b933-4a85-8efa-f9509be48735\\n[2020-11-11 13:30:36Z] Completing processing run id 8f31ff6b-b933-4a85-8efa-f9509be48735.\\n[2020-11-11 13:30:39Z] Submitting 3 runs, first five are: 9d62c7d8:8092053c-9889-4ee5-bf99-b73ef9f7447e,bee5e200:e3d7578a-1e83-4d7a-b424-a7dfea96f3eb,ce546b0d:2865c665-1394-455b-812b-48e1974bb421\\n[2020-11-11 13:47:39Z] Completing processing run id 2865c665-1394-455b-812b-48e1974bb421.\\n[2020-11-11 13:48:49Z] Completing processing run id 8092053c-9889-4ee5-bf99-b73ef9f7447e.\\n[2020-11-11 13:49:01Z] Completing processing run id e3d7578a-1e83-4d7a-b424-a7dfea96f3eb.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"e93ab873\": {\"node_id\": \"e93ab873\", \"name\": \"loan_dataset\"}}, \"module_nodes\": {\"ffbad4f7\": {\"node_id\": \"ffbad4f7\", \"name\": \"Clean Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8f31ff6b-b933-4a85-8efa-f9509be48735\"}, \"9d62c7d8\": {\"node_id\": \"9d62c7d8\", \"name\": \"SGD_tuning\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8092053c-9889-4ee5-bf99-b73ef9f7447e\"}, \"bee5e200\": {\"node_id\": \"bee5e200\", \"name\": \"XGB_tuning\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"e3d7578a-1e83-4d7a-b424-a7dfea96f3eb\"}, \"ce546b0d\": {\"node_id\": \"ce546b0d\", \"name\": \"extratrees_tuning\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"2865c665-1394-455b-812b-48e1974bb421\"}}, \"edges\": [{\"source_node_id\": \"e93ab873\", \"source_node_name\": \"loan_dataset\", \"source_name\": \"data\", \"target_name\": \"loan_dataset\", \"dst_node_id\": \"ffbad4f7\", \"dst_node_name\": \"Clean Data\"}, {\"source_node_id\": \"ffbad4f7\", \"source_node_name\": \"Clean Data\", \"source_name\": \"cleaned_loan_dataset\", \"target_name\": \"cleaned_loan_dataset\", \"dst_node_id\": \"9d62c7d8\", \"dst_node_name\": \"SGD_tuning\"}, {\"source_node_id\": \"ffbad4f7\", \"source_node_name\": \"Clean Data\", \"source_name\": \"cleaned_loan_dataset\", \"target_name\": \"cleaned_loan_dataset\", \"dst_node_id\": \"bee5e200\", \"dst_node_name\": \"XGB_tuning\"}, {\"source_node_id\": \"ffbad4f7\", \"source_node_name\": \"Clean Data\", \"source_name\": \"cleaned_loan_dataset\", \"target_name\": \"cleaned_loan_dataset\", \"dst_node_id\": \"ce546b0d\", \"dst_node_name\": \"extratrees_tuning\"}], \"child_runs\": [{\"run_id\": \"8f31ff6b-b933-4a85-8efa-f9509be48735\", \"name\": \"Clean Data\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:14:47.658497Z\", \"created_time\": \"2020-11-11T13:10:48.557952Z\", \"end_time\": \"2020-11-11T13:30:24.51155Z\", \"duration\": \"0:19:35\", \"run_number\": 56, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:10:48.557952Z\", \"is_reused\": \"\"}, {\"run_id\": \"8092053c-9889-4ee5-bf99-b73ef9f7447e\", \"name\": \"SGD_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:31:18.530135Z\", \"created_time\": \"2020-11-11T13:30:40.537904Z\", \"end_time\": \"2020-11-11T13:48:24.436697Z\", \"duration\": \"0:17:43\", \"run_number\": 59, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:40.537904Z\", \"is_reused\": \"\"}, {\"run_id\": \"e3d7578a-1e83-4d7a-b424-a7dfea96f3eb\", \"name\": \"XGB_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:31:21.832165Z\", \"created_time\": \"2020-11-11T13:30:39.417934Z\", \"end_time\": \"2020-11-11T13:48:49.077202Z\", \"duration\": \"0:18:09\", \"run_number\": 57, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:39.417934Z\", \"is_reused\": \"\"}, {\"run_id\": \"2865c665-1394-455b-812b-48e1974bb421\", \"name\": \"extratrees_tuning\", \"status\": \"Finished\", \"start_time\": \"2020-11-11T13:30:51.60036Z\", \"created_time\": \"2020-11-11T13:30:39.622291Z\", \"end_time\": \"2020-11-11T13:47:27.682124Z\", \"duration\": \"0:16:48\", \"run_number\": 58, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-11-11T13:30:39.622291Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.16.0\"}, \"loading\": false}"
     },
     "metadata": {}
    }
   ],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "source": [
    "## Metrics & Artefacts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model"
   ]
  },
  {
   "source": [
    "### NOTE:\n",
    "- Some `artefacts` like the `KNNImputer` fitted in the `cleanDataStep` will need to be used when the model makes predictions on test data.json\n",
    "- Each `model's` best `hyperparameters` need to be obtained from the HyperDriveSteps for use in the `VotingEnsemble` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run_steps = list(pipeline_run.get_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve metrics from cleanDataStep\n",
    "cleaning_step_metrics = pipeline_run_steps[-1].get_metrics()\n",
    "\n",
    "useful_columns = cleaning_step_metrics[\"useful_columns\"]\n",
    "form_field47_categories = cleaning_step_metrics[\"form_field47_categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "useful_columns:\n ['form_field1', 'form_field2', 'form_field3', 'form_field4', 'form_field5', 'form_field6', 'form_field7', 'form_field8', 'form_field9', 'form_field10', 'form_field12', 'form_field13', 'form_field14', 'form_field16', 'form_field17', 'form_field18', 'form_field19', 'form_field20', 'form_field21', 'form_field22', 'form_field24', 'form_field25', 'form_field26', 'form_field27', 'form_field28', 'form_field29', 'form_field32', 'form_field33', 'form_field34', 'form_field36', 'form_field37', 'form_field38', 'form_field39', 'form_field42', 'form_field43', 'form_field44', 'form_field46', 'form_field47', 'form_field48', 'form_field49', 'form_field50']\n\nform_field47_classes:\n ['charge', 'lending']\n"
     ]
    }
   ],
   "source": [
    "print(\"useful_columns:\\n\", useful_columns)\n",
    "print()\n",
    "print(\"form_field47_classes:\\n\", form_field47_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model kowope-imputer\n"
     ]
    }
   ],
   "source": [
    "# retrieve fitted KNNImputer object and register in workspace\n",
    "pipeline_run_steps[-1].download_file(\"outputs/knnimputer.joblib\", \"outputs/knnimputer.joblib\")\n",
    "imputer = Model.register(ws, model_name=\"kowope-imputer\", model_path=\"./outputs/knnimputer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nBest Run:  HD_43f4d111-d332-4732-b319-73dbd14abc28_0\nArguments:\n('--input_data_name', 'cleaned_loan_dataset')\n('--alpha', '1.5330264302580603')\n('--l1_ratio', '0.059987411998666196')\n\nBest Run:  HD_8ff976be-b48b-4870-bbe3-e3b196c60195_0\nArguments:\n('--input_data_name', 'cleaned_loan_dataset')\n('--early_stopping_rounds', '30')\n('--eval_metric', 'auc')\n('--max_depth', '9')\n('--min_child_weight', '7')\n('--subsample', '0.6924351565333047')\n('--colsample_bytree', '0.8721886373392609')\n('--eta', '0.1573725651962117')\n('--max_delta_step', '6')\n('--scale_pos_weight', '2.8882540753192245')\n\nBest Run:  HD_785b914f-8d41-4dc1-b898-dc86c7e877d5_5\nArguments:\n('--input_data_name', 'cleaned_loan_dataset')\n('--n_estimators', '150')\n('--min_samples_split', '0.000895313339903859')\n('--min_samples_leaf', '0.004288077542077104')\n('--max_features', '0.8928369550899402')\n('--ccp_alpha', '0.0002539867155743947')\n\n"
     ]
    }
   ],
   "source": [
    "parameters = []\n",
    "for child in pipeline_run.get_children(recursive=True, type=\"hyperdrive\"):\n",
    "    best_run = child.get_best_run_by_primary_metric()\n",
    "    print(\"Best Run: \", best_run.id)\n",
    "\n",
    "    # Unncomment the next line to retrieve best_run model for each HyperDrive Run \n",
    "    # best_run.download_file(\"outputs/hyperdrive/model.joblib\", f\"outputs/model_{best_run.id}.joblib\")\n",
    "\n",
    "    # Retrieve and print parameters of best model\n",
    "    parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "\n",
    "    parameters += parameter_values[2:]      # parameter_values 0-1 is always input_data_name\n",
    "\n",
    "    # get num_boost_rounds which was logged during XGBoost HyperDriveRun\n",
    "    if \"num_boost_rounds\" in best_run.get_metrics():\n",
    "        parameters += [\"--num_boost_rounds\", best_run.get_metrics()[\"num_boost_rounds\"]]\n",
    "\n",
    "    def _pairwise(iterable):\n",
    "        a = iter(iterable)\n",
    "        return zip(a, a)\n",
    "\n",
    "    print(\"Arguments:\")\n",
    "    for param in list(_pairwise(parameter_values)):\n",
    "        print(param)\n",
    "    print()"
   ]
  },
  {
   "source": [
    "## VotingClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n\n"
     ]
    }
   ],
   "source": [
    "src = ScriptRunConfig(\n",
    "    source_directory=\"./scripts\",\n",
    "    script=\"voting.py\",\n",
    "    arguments=parameters,\n",
    "    run_config=aml_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "voting_run = experiment.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n'Completed'\n\n"
     ]
    }
   ],
   "source": [
    "voting_run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RunDetails(voting_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nRegistering model kowope-ensemble\n\n"
     ]
    }
   ],
   "source": [
    "voting_run.download_file(\"outputs/model_voting.joblib\", \"outputs/votingensemble.joblib\")\n",
    "model = Model.register(ws, model_name=\"kowope-ensemble\", model_path=\"./outputs/votingensemble.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "from azureml.core import Environment, Image\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice"
   ]
  },
  {
   "source": [
    "## Scoring Script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate scripts/score.py  \n",
    "\"\"\"\n",
    "NOTE: Variables in bracket are loaded from notebook\n",
    "\"\"\"\n",
    "\n",
    "from numpy import array\n",
    "from pandas import DataFrame\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.run import Run\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global imputer\n",
    "\n",
    "    # Voting Ensemble Model\n",
    "    model_name = \"{model.name}\"\n",
    "    model_version = \"{model.version}\"\n",
    "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), model_name, model_version, \"votingensemble.joblib\")\n",
    "\n",
    "    # KNNImputer \n",
    "    imputer_name = \"{imputer.name}\"\n",
    "    imputer_version = \"{imputer.version}\"\n",
    "    imputer_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), imputer_name, imputer_version, \"knnimputer.joblib\")\n",
    "\n",
    "    # Load artefacts \n",
    "    imputer = joblib.load(imputer_path)\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Initialized model\" + time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "\n",
    "def clean_data(data: DataFrame):\n",
    "    columns = {useful_columns}\n",
    "    categories = [array({form_field47_categories}, dtype=object)]\n",
    "\n",
    "    df = data[columns]\n",
    "    enc = OrdinalEncoder()\n",
    "    enc.categories_ = categories\n",
    "    df.form_field47 = enc.transform(df.form_field47.to_frame())\n",
    "    return df\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        input_data = json.loads(data)[\"data\"]\n",
    "        input_df = DataFrame(input_data)\n",
    "        print(\"Input data shape: \", input_df.shape)\n",
    "\n",
    "        cleaned_data = clean_data(input_df)\n",
    "        print(\"Successfully cleaned data | \" + time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        imputed_data = imputer.transform(cleaned_data)\n",
    "        imputed_data = DataFrame(imputed_data, columns=cleaned_data.columns)     # model requires columns names. \n",
    "        print(\"Successfully imputed missing values in data | \" + time.strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        predictions = model.predict(imputed_data)\n",
    "        print(predictions)\n",
    "        print(\"Successfully made predictions | \" + time.strftime(\"%H:%M:%S\"))\n",
    "        return predictions.tolist()\n",
    "    except Exception as e:\n",
    "        # Development only. Change how error is returned for production\n",
    "        return json.dumps(dict.fromkeys([\"error\"], str(e) + time.strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "source": [
    "## Environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"kowope-woro\"\n",
    "try:\n",
    "    env = Environment.get(ws, name=env_name)\n",
    "    TEST_ENVIRONMENT = False\n",
    "except:\n",
    "    env = Environment(name=env_name)\n",
    "    env.python.conda_dependencies = dependencies        # defined above with RunConfiguration object\n",
    "    env.register(workspace=ws)\n",
    "    TEST_ENVIRONMENT = True\n",
    "    print(f\"Env: {env_name} created. Running environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using registered environment: kowope-woro\n"
     ]
    }
   ],
   "source": [
    "if TEST_ENVIRONMENT:\n",
    "    build = env.build(workspace=ws)\n",
    "    build.wait_for_completion(show_output=True)\n",
    "else:\n",
    "    print(f\"Using registered environment: {env_name}\")"
   ]
  },
  {
   "source": [
    "## Configuration & Deployment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NOTE:\n",
    "- `Application Insights` have been enabled here. Together with `print statements` in `score.py`, this will ease `debugging`.\n",
    "- The `CPU and Memory specifications` in deployment configuration arbitrarily, with available resources in mind. A better strategy would be to obtain the `Model Profile`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(\n",
    "    entry_script=\"./scripts/score.py\",\n",
    "    environment=env\n",
    ")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=2, enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, name=\"kowope-predictor\", \n",
    "                       models=[model, imputer], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=deployment_config, \n",
    "                       overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning..\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n\n"
     ]
    }
   ],
   "source": [
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "source": [
    "# Consume Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### NOTE:\n",
    "- By definition, the `run` function in score.py requires a a JSON document with the strucure:\n",
    "```\n",
    "{\n",
    "    \"data\": <model-specific-data-structure>\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_uri = service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found sample data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"data/sample_request_data.txt\") as f:\n",
    "        sample_request_data = json.load(f)\n",
    "    sample_request_data_json = json.dumps(sample_request_data)\n",
    "    # No need to create sample data\n",
    "    CREATE_SAMPLE_DATA = False\n",
    "    print(\"Found sample data.\")\n",
    "except:\n",
    "    CREATE_SAMPLE_DATA = True\n",
    "    # TODO: If True, delete the Schema in sample_request_data.json after sample_request_data.txt created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/Test.csv\"\n",
    "no_sample_observations = 5\n",
    "if CREATE_SAMPLE_DATA:\n",
    "    try:\n",
    "        test = pd.read_csv(test_path)\n",
    "    except:\n",
    "        path = get_data(path=test_path, subset=\"test\")\n",
    "        test = pd.read_csv(path)\n",
    "    finally:\n",
    "        # Create sample request data\n",
    "        sample_request_data = test.iloc[:no_sample_observations, :].to_json(orient=\"table\", index=False)\n",
    "        sample_request_data_json = json.dumps({\"data\": json.loads(sample_request_data)[\"data\"]}, indent=4)\n",
    "        f = open(\"data/sample_request_data.txt\", 'w')\n",
    "        f.write(sample_request_data_json)\n",
    "        f.close()\n",
    "        # print(\"Created sample data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(scoring_uri, sample_request_data_json, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n2020-11-11T21:45:42,062698540+00:00 - iot-server/run \n2020-11-11T21:45:42,063458476+00:00 - gunicorn/run \n2020-11-11T21:45:42,070377906+00:00 - nginx/run \n/usr/sbin/nginx: /azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n2020-11-11T21:45:42,075978373+00:00 - rsyslog/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-11-11T21:45:42,224878068+00:00 - iot-server/finish 1 0\n2020-11-11T21:45:42,226328637+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http://127.0.0.1:31311 (11)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 39\nSPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2020-11-11 21:45:44,533 | root | INFO | Starting up app insights client\nStarting up app insights client\n2020-11-11 21:45:44,534 | root | INFO | Starting up request id generator\nStarting up request id generator\n2020-11-11 21:45:44,534 | root | INFO | Starting up app insight hooks\nStarting up app insight hooks\n2020-11-11 21:45:44,534 | root | INFO | Invoking user's init function\nInvoking user's init function\nInitialized model21:45:44\n2020-11-11 21:45:44,610 | root | INFO | Users's init has completed successfully\nUsers's init has completed successfully\n2020-11-11 21:45:44,612 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\nSkipping middleware: dbg_model_info as it's not enabled.\n2020-11-11 21:45:44,612 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\nSkipping middleware: dbg_resource_usage as it's not enabled.\n2020-11-11 21:45:44,613 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\nScoring timeout is found from os.environ: 60000 ms\n2020-11-11 21:45:56,421 | root | INFO | Swagger file not present\nSwagger file not present\n2020-11-11 21:45:56,421 | root | INFO | 404\n404\n127.0.0.1 - - [11/Nov/2020:21:45:56 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n2020-11-11 21:46:00,088 | root | INFO | Swagger file not present\nSwagger file not present\n2020-11-11 21:46:00,089 | root | INFO | 404\n404\n127.0.0.1 - - [11/Nov/2020:21:46:00 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n2020-11-11 21:46:21,920 | root | INFO | Validation Request Content-Type\nValidation Request Content-Type\n2020-11-11 21:46:21,920 | root | INFO | \tHost: localhost:5001\n\tHost: localhost:5001\n2020-11-11 21:46:21,921 | root | INFO | \tX-Real-Ip: 127.0.0.1\n\tX-Real-Ip: 127.0.0.1\n2020-11-11 21:46:21,921 | root | INFO | \tX-Forwarded-For: 127.0.0.1\n\tX-Forwarded-For: 127.0.0.1\n2020-11-11 21:46:21,921 | root | INFO | \tX-Forwarded-Proto: http\n\tX-Forwarded-Proto: http\n2020-11-11 21:46:21,921 | root | INFO | \tConnection: close\n\tConnection: close\n2020-11-11 21:46:21,921 | root | INFO | \tContent-Length: 9151\n\tContent-Length: 9151\n2020-11-11 21:46:21,921 | root | INFO | \tUser-Agent: python-requests/2.24.0\n\tUser-Agent: python-requests/2.24.0\n2020-11-11 21:46:21,921 | root | INFO | \tAccept: */*\n\tAccept: */*\n2020-11-11 21:46:21,921 | root | INFO | \tAccept-Encoding: gzip, deflate\n\tAccept-Encoding: gzip, deflate\n2020-11-11 21:46:21,921 | root | INFO | \tContent-Type: application/json\n\tContent-Type: application/json\n2020-11-11 21:46:21,921 | root | INFO | \tX-Ms-Request-Id: bf98716f-45b5-4dac-b1ef-e56ff9f45cc9\n\tX-Ms-Request-Id: bf98716f-45b5-4dac-b1ef-e56ff9f45cc9\n2020-11-11 21:46:21,921 | root | INFO | Scoring Timer is set to 60.0 seconds\nScoring Timer is set to 60.0 seconds\nInput data shape:\n(5, 51)\nSuccessfully cleaned data | 21:46:21\nSuccessfully imputed missing values in data | 21:46:22\n[1 1 1 1 0]\nSuccessfully made predictions | 21:46:22\n/azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/python3.6/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\n2020-11-11 21:46:22,376 | root | INFO | 200\n200\n127.0.0.1 - - [11/Nov/2020:21:46:22 +0000] \"POST /score HTTP/1.0\" 200 15 \"-\" \"python-requests/2.24.0\"\n2020-11-11 21:59:39,508 | root | INFO | Swagger file not present\nSwagger file not present\n2020-11-11 21:59:39,508 | root | INFO | 404\n404\n127.0.0.1 - - [11/Nov/2020:21:59:39 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n127.0.0.1 - - [11/Nov/2020:22:17:23 +0000] \"GET /swagger HTTP/1.0\" 404 232 \"-\" \"Mozilla/5.0 (compatible; Nmap Scripting Engine; https://nmap.org/book/nse.html)\"\n2020-11-11 22:58:20,297 | root | INFO | Validation Request Content-Type\nValidation Request Content-Type\n2020-11-11 22:58:20,297 | root | INFO | \tHost: localhost:5001\n\tHost: localhost:5001\n2020-11-11 22:58:20,298 | root | INFO | \tX-Real-Ip: 127.0.0.1\n\tX-Real-Ip: 127.0.0.1\n2020-11-11 22:58:20,298 | root | INFO | \tX-Forwarded-For: 127.0.0.1\n\tX-Forwarded-For: 127.0.0.1\n2020-11-11 22:58:20,298 | root | INFO | \tX-Forwarded-Proto: http\n\tX-Forwarded-Proto: http\n2020-11-11 22:58:20,298 | root | INFO | \tConnection: close\n\tConnection: close\n2020-11-11 22:58:20,298 | root | INFO | \tContent-Length: 5989\n\tContent-Length: 5989\n2020-11-11 22:58:20,298 | root | INFO | \tUser-Agent: python-requests/2.24.0\n\tUser-Agent: python-requests/2.24.0\n2020-11-11 22:58:20,298 | root | INFO | \tAccept: */*\n\tAccept: */*\n2020-11-11 22:58:20,298 | root | INFO | \tAccept-Encoding: gzip, deflate\n\tAccept-Encoding: gzip, deflate\n2020-11-11 22:58:20,298 | root | INFO | \tContent-Type: application/json\n\tContent-Type: application/json\n2020-11-11 22:58:20,298 | root | INFO | \tX-Ms-Request-Id: d791d93b-e497-43ec-9d00-e266f011d778\n\tX-Ms-Request-Id: d791d93b-e497-43ec-9d00-e266f011d778\n2020-11-11 22:58:20,298 | root | INFO | Scoring Timer is set to 60.0 seconds\nScoring Timer is set to 60.0 seconds\nInput data shape:\n(5, 51)\nSuccessfully cleaned data | 22:58:20\nSuccessfully imputed missing values in data | 22:58:20\n[1 1 1 1 0]\nSuccessfully made predictions | 22:58:20\n/azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/python3.6/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\n2020-11-11 22:58:20,575 | root | INFO | 200\n200\n127.0.0.1 - - [11/Nov/2020:22:58:20 +0000] \"POST /score HTTP/1.0\" 200 15 \"-\" \"python-requests/2.24.0\"\n2020-11-11 23:11:41,691 | root | INFO | Validation Request Content-Type\nValidation Request Content-Type\n2020-11-11 23:11:41,692 | root | INFO | \tHost: localhost:5001\n\tHost: localhost:5001\n2020-11-11 23:11:41,692 | root | INFO | \tX-Real-Ip: 127.0.0.1\n\tX-Real-Ip: 127.0.0.1\n2020-11-11 23:11:41,692 | root | INFO | \tX-Forwarded-For: 127.0.0.1\n\tX-Forwarded-For: 127.0.0.1\n2020-11-11 23:11:41,692 | root | INFO | \tX-Forwarded-Proto: http\n\tX-Forwarded-Proto: http\n2020-11-11 23:11:41,692 | root | INFO | \tConnection: close\n\tConnection: close\n2020-11-11 23:11:41,692 | root | INFO | \tContent-Length: 5989\n\tContent-Length: 5989\n2020-11-11 23:11:41,692 | root | INFO | \tUser-Agent: python-requests/2.24.0\n\tUser-Agent: python-requests/2.24.0\n2020-11-11 23:11:41,692 | root | INFO | \tAccept: */*\n\tAccept: */*\n2020-11-11 23:11:41,692 | root | INFO | \tAccept-Encoding: gzip, deflate\n\tAccept-Encoding: gzip, deflate\n2020-11-11 23:11:41,692 | root | INFO | \tContent-Type: application/json\n\tContent-Type: application/json\n2020-11-11 23:11:41,692 | root | INFO | \tX-Ms-Request-Id: 10155552-23fe-42ef-96d7-9deefa40372c\n\tX-Ms-Request-Id: 10155552-23fe-42ef-96d7-9deefa40372c\n2020-11-11 23:11:41,692 | root | INFO | Scoring Timer is set to 60.0 seconds\nScoring Timer is set to 60.0 seconds\nInput data shape:\n(5, 51)\nSuccessfully cleaned data | 23:11:41\nSuccessfully imputed missing values in data | 23:11:41\n[1 1 1 1 0]\nSuccessfully made predictions | 23:11:41\n/azureml-envs/azureml_0e0eddfe931ab68286a2cca9e6d0a9b5/lib/python3.6/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\n2020-11-11 23:11:41,964 | root | INFO | 200\n200\n127.0.0.1 - - [11/Nov/2020:23:11:41 +0000] \"POST /score HTTP/1.0\" 200 15 \"-\" \"python-requests/2.24.0\"\n\n\n"
     ]
    }
   ],
   "source": [
    "# Examine the logs to see the \n",
    "logs = service.get_logs()\n",
    "print(logs)"
   ]
  },
  {
   "source": [
    "# Clean-Up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# delete webservice\n",
    "Webservice(ws, \"kowope-predictor\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Deleting.....\n"
     ]
    }
   ],
   "source": [
    "# delete compute target\n",
    "aml_compute.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}